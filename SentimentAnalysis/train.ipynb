{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we perform the training loops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataFrameManager.dataframeManager import DataFrameManager\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATASET_COLUMNS = [\"text\", \"label\"]#[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "MODEL_NAME = 'roberta'\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameManage = DataFrameManager()\n",
    "\n",
    "train_df = dataFrameManage.load_dataframe(filepath=\"Data/twitter-datasets/preprocessed/train_preprocessed.csv\", encoding=DATASET_ENCODING, preprocess=False)\n",
    "test_df = dataFrameManage.load_dataframe(filepath=\"Data/twitter-datasets/preprocessed/test_preprocessed.csv\", encoding=DATASET_ENCODING, preprocess=False)\n",
    "\n",
    "encode_map = {\"NEGATIVE\" : 0, \"POSITIVE\" : 1}\n",
    "\n",
    "# take the first 18000 rows\n",
    "train_df = train_df[:18000]\n",
    "test_df = test_df[:4500]\n",
    "\n",
    "train_labels = train_df[\"target\"].map(encode_map).to_list()\n",
    "test_labels = test_df[\"target\"].map(encode_map).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_embeddings = np.load(f'Data/mock-data/train_embeddings_{MODEL_NAME}.npy', allow_pickle=True)\n",
    "# test_embeddings = np.load(f'Data/mock-data/test_embeddings_{MODEL_NAME}.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Start training\n",
    "\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'C': [10.0, 50.0],\n",
    "#     'max_iter': [1000, 1500],\n",
    "#     'penalty': ['l2']\n",
    "# }\n",
    "\n",
    "# # # Create the Logistic Regression classifier\n",
    "# classifier_lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(classifier_lr, param_grid, cv=5)\n",
    "# grid_search.fit(train_embeddings, train_labels)\n",
    "\n",
    "# # Get the best hyperparameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"Best Score: \", best_score)\n",
    "\n",
    "# # Fit the model with the best hyperparameters on the entire training data\n",
    "# best_classifier_lr = LogisticRegression(**best_params)\n",
    "# best_classifier_lr.fit(train_embeddings, train_labels)\n",
    "\n",
    "# # Predict on the test set\n",
    "# predictions_lr = best_classifier_lr.predict(test_embeddings)\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# accuracy_lr = accuracy_score(test_labels, predictions_lr)\n",
    "# print(\"Accuracy score for Logistic Regression: \", accuracy_lr)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the SVM classifier\n",
    "# from sklearn import svm\n",
    "\n",
    "\n",
    "# svm_classifier = svm.SVC()\n",
    "# svm_classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "# # Test the SVM classifier\n",
    "# predictions = svm_classifier.predict(test_embeddings)\n",
    "# accuracy = accuracy_score(test_labels, predictions)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'eta': [0.1, 0.3],\n",
    "#     'max_depth': [3, 6],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0],\n",
    "#     'objective': ['multi:softmax'],\n",
    "#     'num_class': [NUM_CLASSES]\n",
    "# }\n",
    "\n",
    "# # Create the XGBoost classifier\n",
    "# classifier_xgb = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# # Perform grid search with cross-validation\n",
    "# grid_search = GridSearchCV(classifier_xgb, param_grid, cv=5)\n",
    "# grid_search.fit(train_embeddings, train_labels)\n",
    "\n",
    "# # Get the best hyperparameters and best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(\"Best Hyperparameters: \", best_params)\n",
    "# print(\"Best Score: \", best_score)\n",
    "\n",
    "# # Fit the model with the best hyperparameters on the entire training data\n",
    "# best_classifier_xgb = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "# best_classifier_xgb.fit(train_embeddings, train_labels)\n",
    "\n",
    "# # Predict on the test set\n",
    "# predictions_xgb = best_classifier_xgb.predict(test_embeddings)\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# accuracy_xgb = accuracy_score(test_labels, predictions_xgb)\n",
    "# print(\"Accuracy score for XGBoost: \", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_xgb = xgb.XGBClassifier(random_state=42, objective='multi:softmax', eta=0.3, max_depth=7, subsample=0.8, colsample_bytree=0.8, num_class = 3)\n",
    "# classifier_xgb.fit(train_embeddings, train_labels)\n",
    "# predictions_xgb = classifier_xgb.predict(test_embeddings)\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# accuracy_xgb = accuracy_score(test_labels, predictions_xgb)\n",
    "# print(\"Accuracy score for XGBoost: \", accuracy_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Define the neural network model\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 2 * hidden_size)\n",
    "#         self.elu1 = nn.ELU()\n",
    "#         self.fc2 = nn.Linear(2 * hidden_size,  hidden_size)\n",
    "#         self.elu2 = nn.ELU()\n",
    "#         self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "#         self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.elu1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.elu2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.dropout(x)\n",
    "#         return x\n",
    "\n",
    "# # Convert the data to PyTorch tensors\n",
    "# train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32)\n",
    "# train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "# test_embeddings_tensor = torch.tensor(test_embeddings, dtype=torch.float32)\n",
    "# test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# # Create the neural network model\n",
    "# model = NeuralNetwork(train_embeddings_tensor.shape[1], 256, NUM_CLASSES)\n",
    "\n",
    "# # Define the loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 20\n",
    "# batch_size = 32\n",
    "# train_loss_history = []\n",
    "# val_loss_history = []\n",
    "# train_acc_history = []\n",
    "# val_acc_history = []\n",
    "\n",
    "# num_batches = int(np.ceil(len(train_embeddings) / batch_size))\n",
    "\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 5\n",
    "# early_stop_counter = 0\n",
    "\n",
    "# with tqdm(total=num_epochs, desc='Epoch', unit='epoch') as pbar:\n",
    "#     for epoch in range(num_epochs):\n",
    "#         epoch_train_loss = 0.0\n",
    "#         epoch_val_loss = 0.0\n",
    "#         epoch_train_acc = 0.0\n",
    "#         epoch_val_acc = 0.0\n",
    "\n",
    "#         model.train()\n",
    "#         for i in range(num_batches):\n",
    "#             start_idx = i * batch_size\n",
    "#             end_idx = min((i + 1) * batch_size, len(train_embeddings))\n",
    "#             batch_embeddings = train_embeddings_tensor[start_idx:end_idx]\n",
    "#             batch_labels = train_labels_tensor[start_idx:end_idx]\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(batch_embeddings)\n",
    "#             loss = criterion(outputs, batch_labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             epoch_train_loss += loss.item()\n",
    "#             _, train_predicted_labels = torch.max(outputs, 1)\n",
    "#             epoch_train_acc += accuracy_score(batch_labels.numpy(), train_predicted_labels.numpy())\n",
    "\n",
    "#         epoch_train_loss /= num_batches\n",
    "#         epoch_train_acc /= num_batches\n",
    "\n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             val_outputs = model(test_embeddings_tensor)\n",
    "#             val_loss = criterion(val_outputs, test_labels_tensor)\n",
    "#             epoch_val_loss = val_loss.item()\n",
    "#             _, val_predicted_labels = torch.max(val_outputs, 1)\n",
    "#             epoch_val_acc = accuracy_score(test_labels_tensor.numpy(), val_predicted_labels.numpy())\n",
    "\n",
    "#         train_loss_history.append(epoch_train_loss)\n",
    "#         val_loss_history.append(epoch_val_loss)\n",
    "#         train_acc_history.append(epoch_train_acc)\n",
    "#         val_acc_history.append(epoch_val_acc)\n",
    "\n",
    "#         pbar.set_postfix({'Train Loss': epoch_train_loss, 'Val Loss': epoch_val_loss,\n",
    "#                           'Train Acc': epoch_train_acc, 'Val Acc': epoch_val_acc})\n",
    "#         pbar.update()\n",
    "\n",
    "#         if epoch_val_loss < best_val_loss:\n",
    "#             best_val_loss = epoch_val_loss\n",
    "#             early_stop_counter = 0\n",
    "#             # Save the model parameters\n",
    "#             torch.save(model.state_dict(), 'best_model.pt')\n",
    "#         else:\n",
    "#             early_stop_counter += 1\n",
    "#             if early_stop_counter >= patience:\n",
    "#                 print(\"Early stopping triggered. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "#                 break\n",
    "\n",
    "# # Load the best model\n",
    "# model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# # Convert the tensors to numpy arrays\n",
    "# with torch.no_grad():\n",
    "#     predicted_labels = model(test_embeddings_tensor)\n",
    "#     predicted_labels = torch.argmax(predicted_labels, dim=1).numpy()\n",
    "#     true_labels = test_labels_tensor.numpy()\n",
    "\n",
    "# # Calculate the accuracy score\n",
    "# accuracy_nn = accuracy_score(true_labels, predicted_labels)\n",
    "# print(\"Accuracy score for Neural Network: \", accuracy_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "NUM_CLASSES = 2\n",
    "ROBERT_LARGE_EMBEDDINGS_SIZE = 768\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = RobertaForSequenceClassification.from_pretrained('Data/roberta_base_fine_tuned/')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('Data/roberta_base_fine_tuned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, max_len, targets):\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "        label = self.targets[index]\n",
    "    \n",
    "        return text, torch.tensor(label, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (18000, 2)\n",
      "TEST Dataset: (4500, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_set = SentimentData(train_df, MAX_LEN, train_labels)\n",
    "valid_set = SentimentData(test_df, MAX_LEN, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set)\n",
    "valid_loader = DataLoader(valid_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv(\"Data/twitter-datasets/preprocessed/test_data_preprocessed.csv\", names=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "tokenized_inputs = tokenizer.batch_encode_plus(prediction_data[\"text\"], padding=True, truncation=True, return_tensors='pt')\n",
    "inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "# Perform forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "predicted_labels = [-1 if item==0 else 1 for item in predicted_labels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id': range(1, len(predicted_labels) + 1), 'Prediction': predicted_labels})\n",
    "df.to_csv(\"Data/twitter-datasets/prediction.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine Tuning the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[1;32m     44\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39mlogits, labels)\n\u001b[0;32m---> 45\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     46\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Computational-Intelligence-Lab-Sentiment-analysis/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Computational-Intelligence-Lab-Sentiment-analysis/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up RoBERTa model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "model = model.to(device)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Lists to store training and validation loss/accuracy for each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracies = []\n",
    "valid_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    train_correct = 0\n",
    "    valid_correct = 0\n",
    "    train_total = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = tokenizer.batch_encode_plus(inputs, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs['input_ids'].size(0)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_loader = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "    for inputs, labels in valid_loader:\n",
    "        inputs = tokenizer.batch_encode_plus(inputs, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        valid_loss += loss.item() * inputs['input_ids'].size(0)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        valid_total += labels.size(0)\n",
    "        valid_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate average losses and accuracies\n",
    "    train_loss = train_loss / len(train_set)\n",
    "    valid_loss = valid_loss / len(valid_set)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    valid_accuracy = valid_correct / valid_total\n",
    "    \n",
    "    # Append losses and accuracies to the lists\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Valid Loss: {valid_loss:.4f} - Train Acc: {train_accuracy:.4f} - Valid Acc: {valid_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(valid_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
