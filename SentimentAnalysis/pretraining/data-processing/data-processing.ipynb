{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset extractor\n",
    "Disclaymer: To run this notebook, launch pyspark (command \"pyspark --master local[*number of cores*]\") from the folder containing the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from utility_functions import save_rdd_to_json_file, merge_files\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get directory\n",
    "directory = os.path.dirname(os.getcwd()).replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Define paths\n",
    "path_complete_dataset = directory + \"/data/datasets/All_Amazon_Review.json\"\n",
    "path_merged_dataset = directory + \"/data/datasets/dataset.json\"\n",
    "path_dataset_directory = directory + \"/data/datasets/dataset\"\n",
    "# Define number of examples to take and limit for number of characters.\n",
    "limit = 1000000\n",
    "upper_limit_characters = 2300\n",
    "lower_limit_characters = 650"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.executor.memory\", \"32g\") \\\n",
    "    .config(\"spark.driver.memory\", \"32g\") \\\n",
    "    .config(\"spark.network.timeout\", \"1200s\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"12g\")\\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"1200s\")\\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Xmx32g -Xms12g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "dataset = spark.read.json(path_complete_dataset, schema=\"overall float, reviewText string\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd of items with overall 1\n",
    "dataset1 = dataset.rdd.filter(lambda obj: obj[\"overall\"] == 1.0 and obj[\"reviewText\"] is not None)\\\n",
    "    .filter(lambda obj: lower_limit_characters <= len(obj[\"reviewText\"]) <= upper_limit_characters)\\\n",
    "\n",
    "# Estimate the total count of elements in the RDD\n",
    "estimated_count = dataset1.countApprox(timeout=100, confidence=0.95)\n",
    "\n",
    "# Calculate the fraction based on the desired sample size and estimated count\n",
    "fraction = min(limit / estimated_count, 1.0)\n",
    "\n",
    "# Sample items and save file\n",
    "save_rdd_to_json_file(path_dataset_directory + \"/dataset1\", dataset1.sample(False, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd of items with overall 2\n",
    "dataset2 = dataset.rdd.filter(lambda obj: obj[\"overall\"] == 2.0 and obj[\"reviewText\"] is not None)\\\n",
    "    .filter(lambda obj: lower_limit_characters <= len(obj[\"reviewText\"].replace(\" \", \"\")) <= upper_limit_characters)\n",
    "\n",
    "# Estimate the total count of elements in the RDD\n",
    "estimated_count = dataset2.countApprox(timeout=100, confidence=0.95)\n",
    "\n",
    "# Calculate the fraction based on the desired sample size and estimated count\n",
    "fraction = min(limit / estimated_count, 1.0)\n",
    "\n",
    "# Sample items and save file\n",
    "save_rdd_to_json_file(path_dataset_directory + \"/dataset2\", dataset2.sample(False, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd of items with overall 3\n",
    "dataset3 = dataset.rdd.filter(lambda obj: obj[\"overall\"] == 3.0 and obj[\"reviewText\"] is not None)\\\n",
    "    .filter(lambda obj: lower_limit_characters <= len(obj[\"reviewText\"].replace(\" \", \"\")) <= upper_limit_characters)\n",
    "\n",
    "# Estimate the total count of elements in the RDD\n",
    "estimated_count = dataset3.countApprox(timeout=100, confidence=0.95)\n",
    "\n",
    "# Calculate the fraction based on the desired sample size and estimated count\n",
    "fraction = min(limit / estimated_count, 1.0)\n",
    "\n",
    "# Sample items and save file\n",
    "save_rdd_to_json_file(path_dataset_directory + \"/dataset3\", dataset3.sample(False, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd of items with overall 4\n",
    "dataset4 = dataset.rdd.filter(lambda obj: obj[\"overall\"] == 4.0 and obj[\"reviewText\"] is not None)\\\n",
    "    .filter(lambda obj: lower_limit_characters <= len(obj[\"reviewText\"].replace(\" \", \"\")) <= upper_limit_characters)\n",
    "\n",
    "# Estimate the total count of elements in the RDD\n",
    "estimated_count = dataset4.countApprox(timeout=100, confidence=0.95)\n",
    "\n",
    "# Calculate the fraction based on the desired sample size and estimated count\n",
    "fraction = min(limit / estimated_count, 1.0)\n",
    "\n",
    "# Sample items and save file\n",
    "save_rdd_to_json_file(path_dataset_directory + \"/dataset4\", dataset4.sample(False, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rdd of items with overall 5\n",
    "dataset5 = dataset.rdd.filter(lambda obj: obj[\"overall\"] == 5.0 and obj[\"reviewText\"] is not None)\\\n",
    "    .filter(lambda obj: lower_limit_characters <= len(obj[\"reviewText\"].replace(\" \", \"\")) <= upper_limit_characters)\n",
    "\n",
    "# Estimate the total count of elements in the RDD\n",
    "estimated_count = dataset5.countApprox(timeout=100, confidence=0.95)\n",
    "\n",
    "# Calculate the fraction based on the desired sample size and estimated count\n",
    "fraction = min(limit / estimated_count, 1.0)\n",
    "\n",
    "# Sample items and save file\n",
    "save_rdd_to_json_file(path_dataset_directory + \"/dataset5\", dataset5.sample(False, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create dataset from files produced by previous cells\n",
    "merge_files(path_dataset_directory, path_merged_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
